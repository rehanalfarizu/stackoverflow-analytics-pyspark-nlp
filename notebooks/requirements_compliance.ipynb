{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6566102e",
   "metadata": {},
   "source": [
    "# UAS Compliance Notebook\n",
    "\n",
    "Tujuan: Membuktikan kepatuhan terhadap persyaratan UAS Big Data Predictive Analytics.\n",
    "\n",
    "Ringkasan cakupan:\n",
    "- 5V: Volume, Variety, Veracity, Value (≥3 terpenuhi)\n",
    "- File system: local FS digunakan (bisa HDFS), penyimpanan Parquet\n",
    "- Batch + MapReduce: RDD `map`, `flatMap`, `reduceByKey`, `partitionBy`, dll.\n",
    "- EDA: Statistik & visualisasi\n",
    "- Preprocessing: casting, missing value handling, cleaning\n",
    "- Spark SQL: CTE, subquery, SQL hint (broadcast)\n",
    "- RDD Ops: reduceByKey, groupByKey, combineByKey, aggregateByKey\n",
    "- ML: Supervised (RF, GBT), Unsupervised (LDA); komparasi ≥2 algoritma\n",
    "- Hyperparameter tuning: `ParamGridBuilder` + `CrossValidator`\n",
    "- Evaluasi: Accuracy, Precision, Recall, F1 (opsional AUC untuk binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b48613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/16 12:34:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Setup & Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"UAS-Compliance\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(f\"Spark {spark.version} ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c20d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset (gunakan processed/questions jika tersedia)\n",
    "import os\n",
    "processed_path = \"data/processed/questions\"\n",
    "\n",
    "if os.path.exists(processed_path):\n",
    "    df = spark.read.parquet(processed_path)\n",
    "else:\n",
    "    sample_data = [\n",
    "        (1, 1, \"How to read CSV in Python pandas?\", \n",
    "         \"I want to read a CSV file.\", \"<python><pandas><csv>\", 10, 1500, 3, 1, \"2024-01-15\"),\n",
    "        (2, 1, \"JavaScript async await tutorial\",\n",
    "         \"Can someone explain async/await?\", \"<javascript><async><promise>\", 25, 3200, 5, 1, \"2024-02-20\"),\n",
    "        (3, 1, \"Docker container networking\",\n",
    "         \"Connect containers in Docker.\", \"<docker><networking><containers>\", 15, 2100, 4, 1, \"2024-03-10\"),\n",
    "    ]\n",
    "    schema = StructType([\n",
    "        StructField(\"Id\", IntegerType(), True),\n",
    "        StructField(\"PostTypeId\", IntegerType(), True),\n",
    "        StructField(\"Title\", StringType(), True),\n",
    "        StructField(\"Body\", StringType(), True),\n",
    "        StructField(\"Tags\", StringType(), True),\n",
    "        StructField(\"Score\", IntegerType(), True),\n",
    "        StructField(\"ViewCount\", IntegerType(), True),\n",
    "        StructField(\"AnswerCount\", IntegerType(), True),\n",
    "        StructField(\"HasAcceptedAnswer\", IntegerType(), True),\n",
    "        StructField(\"CreationDate\", StringType(), True),\n",
    "    ])\n",
    "    df = spark.createDataFrame(sample_data, schema)\n",
    "\n",
    "# Preprocessing: casting & missing\n",
    "df = df.withColumn(\"CreationDate\", F.to_timestamp(\"CreationDate\"))\n",
    "df = df.fillna({\"Score\": 0, \"ViewCount\": 0, \"AnswerCount\": 0, \"HasAcceptedAnswer\": 0})\n",
    "df = df.withColumn(\"Year\", F.year(\"CreationDate\")).withColumn(\"Month\", F.month(\"CreationDate\"))\n",
    "\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bd7cf",
   "metadata": {},
   "source": [
    "## 5V Coverage\n",
    "- Volume: Stack Overflow dump (≥100GB) siap diproses (pipeline mendukung Parquet & Spark).\n",
    "- Variety: XML (terstruktur), teks HTML (tidak terstruktur), tags.\n",
    "- Veracity: Cleaning HTML, missing value handling, casting tipe.\n",
    "- Value: Model prediktif kualitas pertanyaan & topik (LDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan ke file system (local FS; HDFS dapat digunakan dengan path hdfs://)\n",
    "output_path = \"data/output/uas_compliance_parquet\"\n",
    "(\n",
    "    df.write.mode(\"overwrite\").partitionBy(\"Year\", \"Month\").parquet(output_path)\n",
    ")\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b9ea05",
   "metadata": {},
   "source": [
    "## Spark SQL: CTE, subquery, hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register temp views\n",
    "df.createOrReplaceTempView(\"questions\")\n",
    "\n",
    "# CTE + subquery + hint(broadcast)\n",
    "sql_query = \"\"\"\n",
    "WITH popular AS (\n",
    "  SELECT Id, Title, Score, ViewCount, Year, Month\n",
    "  FROM questions\n",
    "  WHERE Score >= 10\n",
    "),\n",
    "agg AS (\n",
    "  SELECT Year, Month, COUNT(*) AS cnt, AVG(Score) AS avg_score\n",
    "  FROM questions\n",
    "  GROUP BY Year, Month\n",
    ")\n",
    "SELECT /*+ BROADCAST(agg) */ p.Year, p.Month, p.Title, p.Score, a.avg_score\n",
    "FROM popular p\n",
    "JOIN agg a ON a.Year = p.Year AND a.Month = p.Month\n",
    "WHERE p.Score > (SELECT AVG(Score) FROM questions)\n",
    "ORDER BY p.Year, p.Month, p.Score DESC\n",
    "\"\"\"\n",
    "res = spark.sql(sql_query)\n",
    "res.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f71dfb",
   "metadata": {},
   "source": [
    "## RDD MapReduce Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.etl.rdd_ops import (\n",
    "    tags_count_mapreduce,\n",
    "    monthly_question_mapreduce,\n",
    "    tag_score_aggregate,\n",
    "    tag_posts_groupbykey,\n",
    "    tag_stats_combinebykey,\n",
    ")\n",
    "\n",
    "print(\"[RDD] MapReduce counts\")\n",
    "tags_df = tags_count_mapreduce(df)\n",
    "tags_df.show(10)\n",
    "\n",
    "print(\"[RDD] Monthly counts reduceByKey + partitionBy\")\n",
    "monthly_df = monthly_question_mapreduce(df)\n",
    "monthly_df.show(10)\n",
    "\n",
    "print(\"[RDD] aggregateByKey\")\n",
    "agg_df = tag_score_aggregate(df)\n",
    "agg_df.show(10)\n",
    "\n",
    "print(\"[RDD] groupByKey\")\n",
    "gpk_df = tag_posts_groupbykey(df)\n",
    "gpk_df.show(10)\n",
    "\n",
    "print(\"[RDD] combineByKey\")\n",
    "cbk_df = tag_stats_combinebykey(df)\n",
    "cbk_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c2a7d",
   "metadata": {},
   "source": [
    "## ML: Komparasi Algoritma + Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88405f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Binary label (GBT hanya mendukung 0/1, jadi gunakan binary: high quality vs not)\n",
    "# Label 1 = High quality (score >= 10), Label 0 = Not high quality\n",
    "df_ml = df.withColumn(\n",
    "    \"label\",\n",
    "    F.when(F.col(\"Score\") >= 10, 1.0).otherwise(0.0)\n",
    ").withColumn(\"Text\", F.concat_ws(\" \", F.col(\"Title\"), F.col(\"Body\")))\n",
    "\n",
    "print(\"Label distribution:\")\n",
    "df_ml.groupBy(\"label\").count().show()\n",
    "\n",
    "# NLP features\n",
    "tokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"Words\")\n",
    "remover = StopWordsRemover(inputCol=\"Words\", outputCol=\"FilteredWords\")\n",
    "htf = HashingTF(inputCol=\"FilteredWords\", outputCol=\"RawFeatures\", numFeatures=500)\n",
    "idf = IDF(inputCol=\"RawFeatures\", outputCol=\"TFIDF\")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"TFIDF\", \"ViewCount\", \"AnswerCount\"], outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Model 1: Random Forest\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
    "\n",
    "# Model 2: Logistic Regression (mendukung multiclass)\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[tokenizer, remover, htf, idf, assembler, rf])\n",
    "pipeline_lr = Pipeline(stages=[tokenizer, remover, htf, idf, assembler, lr])\n",
    "\n",
    "# Evaluators\n",
    "eval_acc = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "eval_f1 = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "eval_precision = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "eval_recall = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "eval_auc = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "\n",
    "# Hyperparameter tuning untuk RF dengan CrossValidator\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [3, 5]) \\\n",
    "    .build()\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline_rf,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=eval_f1,\n",
    "    numFolds=2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "df_train, df_test = df_ml.randomSplit([0.7, 0.3], seed=42)\n",
    "print(f\"Train: {df_train.count()}, Test: {df_test.count()}\")\n",
    "\n",
    "# Train RF dengan CrossValidator (Hyperparameter Tuning)\n",
    "print(\"Training Random Forest with CrossValidator...\")\n",
    "cv_model = cv.fit(df_train)\n",
    "rf_preds = cv_model.bestModel.transform(df_test)\n",
    "\n",
    "# Evaluate RF\n",
    "rf_acc = eval_acc.evaluate(rf_preds)\n",
    "rf_f1 = eval_f1.evaluate(rf_preds)\n",
    "rf_precision = eval_precision.evaluate(rf_preds)\n",
    "rf_recall = eval_recall.evaluate(rf_preds)\n",
    "rf_auc = eval_auc.evaluate(rf_preds)\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = pipeline_lr.fit(df_train)\n",
    "lr_preds = lr_model.transform(df_test)\n",
    "\n",
    "# Evaluate LR\n",
    "lr_acc = eval_acc.evaluate(lr_preds)\n",
    "lr_f1 = eval_f1.evaluate(lr_preds)\n",
    "lr_precision = eval_precision.evaluate(lr_preds)\n",
    "lr_recall = eval_recall.evaluate(lr_preds)\n",
    "lr_auc = eval_auc.evaluate(lr_preds)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<15} {'Random Forest':<18} {'Logistic Regression':<18}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<15} {rf_acc:<18.4f} {lr_acc:<18.4f}\")\n",
    "print(f\"{'F1-Score':<15} {rf_f1:<18.4f} {lr_f1:<18.4f}\")\n",
    "print(f\"{'Precision':<15} {rf_precision:<18.4f} {lr_precision:<18.4f}\")\n",
    "print(f\"{'Recall':<15} {rf_recall:<18.4f} {lr_recall:<18.4f}\")\n",
    "print(f\"{'AUC-ROC':<15} {rf_auc:<18.4f} {lr_auc:<18.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Best model selection\n",
    "best_model = \"Random Forest\" if rf_f1 >= lr_f1 else \"Logistic Regression\"\n",
    "print(f\"Best Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc0bce",
   "metadata": {},
   "source": [
    "## Kesimpulan Kepatuhan\n",
    "- Batch processing + MapReduce: TERPENUHI (RDD ops lengkap)\n",
    "- EDA & Visualisasi: TERPENUHI (lihat notebook analitik + dashboard)\n",
    "- Preprocessing kualitas data: TERPENUHI (casting, fillna, cleaning di pipeline)\n",
    "- Spark SQL (CTE, subquery, hint): TERPENUHI\n",
    "- RDD partition & byKey ops: TERPENUHI\n",
    "- ML komparasi (RF vs GBT) + Hyperparameter tuning (RF): TERPENUHI\n",
    "- Evaluasi model (Accuracy, F1): TERPENUHI (bisa tambah Precision/Recall/AUC bila target binary)\n",
    "- 5V (≥3): TERPENUHI (Volume, Variety, Veracity, Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d383a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Compliance notebook completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Big Data Mining)",
   "language": "python",
   "name": "bigdata-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
