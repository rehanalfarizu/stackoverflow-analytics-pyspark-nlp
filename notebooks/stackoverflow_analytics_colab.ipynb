{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa09cdf9",
   "metadata": {},
   "source": [
    "# Stack Overflow Analytics dengan PySpark dan NLP\n",
    "\n",
    "**UAS - Big Data Predictive Analytics Lanjut**\n",
    "\n",
    "**Muhammad Raihan Alfarizi - 23.11.5548**\n",
    "\n",
    "Notebook ini menganalisis data **Stack Overflow** secara langsung menggunakan:\n",
    "- Apache Spark (PySpark) untuk Big Data Processing\n",
    "- NLTK untuk Natural Language Processing\n",
    "- Spark MLlib untuk Machine Learning\n",
    "\n",
    "Dataset diambil langsung dari **Stack Exchange API** (data real-time).\n",
    "\n",
    "---\n",
    "\n",
    "## Persyaratan UAS yang Tercakup:\n",
    "1. Dataset 5V (Volume, Variety, Veracity, Value)\n",
    "2. File System (Parquet storage)\n",
    "3. Batch Processing + MapReduce (RDD operations)\n",
    "4. EDA + Visualisasi\n",
    "5. Preprocessing data\n",
    "6. Spark SQL (CTE, subquery, hint)\n",
    "7. RDD Operations (reduceByKey, groupByKey, combineByKey, aggregateByKey)\n",
    "8. ML Komparasi 2 Algoritma\n",
    "9. Hyperparameter Tuning\n",
    "10. Evaluasi Model (Accuracy, F1, Precision, Recall, AUC-ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952aa45",
   "metadata": {},
   "source": [
    "## 1. Setup dan Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8fae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install pyspark==3.5.0 pandas numpy nltk matplotlib seaborn plotly requests -q\n",
    "\n",
    "# Download NLTK data\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5119d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StackOverflow-Analytics\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(\"Spark Session created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341776e0",
   "metadata": {},
   "source": [
    "## 2. Fetch Data dari Stack Exchange API\n",
    "\n",
    "Mengambil data langsung dari Stack Overflow menggunakan Stack Exchange API.\n",
    "\n",
    "**Catatan:** \n",
    "- API limit: 300 requests/day tanpa API key\n",
    "- Data yang diambil: Questions dengan tags python, javascript, java\n",
    "- Periode: 30 hari terakhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack Exchange API Configuration\n",
    "BASE_URL = \"https://api.stackexchange.com/2.3\"\n",
    "SITE = \"stackoverflow\"\n",
    "\n",
    "def fetch_questions(tag, page=1, pagesize=100):\n",
    "    \"\"\"Fetch questions from Stack Overflow API.\"\"\"\n",
    "    url = f\"{BASE_URL}/questions\"\n",
    "    params = {\n",
    "        \"order\": \"desc\",\n",
    "        \"sort\": \"votes\",\n",
    "        \"tagged\": tag,\n",
    "        \"site\": SITE,\n",
    "        \"page\": page,\n",
    "        \"pagesize\": pagesize,\n",
    "        \"filter\": \"withbody\"  # Include body in response\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def fetch_multiple_tags(tags, pages_per_tag=3):\n",
    "    \"\"\"Fetch questions for multiple tags.\"\"\"\n",
    "    all_questions = []\n",
    "    \n",
    "    for tag in tags:\n",
    "        print(f\"Fetching questions for tag: {tag}\")\n",
    "        for page in range(1, pages_per_tag + 1):\n",
    "            result = fetch_questions(tag, page=page)\n",
    "            if result and \"items\" in result:\n",
    "                all_questions.extend(result[\"items\"])\n",
    "                print(f\"  Page {page}: {len(result['items'])} questions\")\n",
    "            time.sleep(0.5)  # Rate limiting\n",
    "    \n",
    "    print(f\"\\nTotal questions fetched: {len(all_questions)}\")\n",
    "    return all_questions\n",
    "\n",
    "# Fetch data untuk beberapa tags populer\n",
    "tags = [\"python\", \"javascript\", \"java\", \"pyspark\", \"machine-learning\"]\n",
    "questions_data = fetch_multiple_tags(tags, pages_per_tag=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb164fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data structure\n",
    "if questions_data:\n",
    "    sample = questions_data[0]\n",
    "    print(\"Sample Question Structure:\")\n",
    "    print(json.dumps({k: type(v).__name__ for k, v in sample.items()}, indent=2))\n",
    "    print(f\"\\nSample Title: {sample.get('title', 'N/A')[:80]}...\")\n",
    "    print(f\"Score: {sample.get('score', 0)}\")\n",
    "    print(f\"View Count: {sample.get('view_count', 0)}\")\n",
    "    print(f\"Tags: {sample.get('tags', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93333870",
   "metadata": {},
   "source": [
    "## 3. ETL Pipeline - Transform ke Spark DataFrame\n",
    "\n",
    "Transformasi data JSON dari API ke Spark DataFrame dengan schema yang terstruktur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform API data to structured format\n",
    "def clean_html(text):\n",
    "    \"\"\"Remove HTML tags from text.\"\"\"\n",
    "    if text:\n",
    "        clean = re.sub(r'<[^>]+>', '', text)\n",
    "        return clean.strip()\n",
    "    return \"\"\n",
    "\n",
    "# Extract relevant fields from API response\n",
    "processed_data = []\n",
    "for q in questions_data:\n",
    "    processed_data.append({\n",
    "        \"question_id\": q.get(\"question_id\"),\n",
    "        \"title\": q.get(\"title\", \"\"),\n",
    "        \"body\": clean_html(q.get(\"body\", \"\")),\n",
    "        \"tags\": q.get(\"tags\", []),\n",
    "        \"tags_str\": \"<\" + \"><\".join(q.get(\"tags\", [])) + \">\" if q.get(\"tags\") else \"\",\n",
    "        \"score\": q.get(\"score\", 0),\n",
    "        \"view_count\": q.get(\"view_count\", 0),\n",
    "        \"answer_count\": q.get(\"answer_count\", 0),\n",
    "        \"is_answered\": 1 if q.get(\"is_answered\", False) else 0,\n",
    "        \"creation_date\": datetime.fromtimestamp(q.get(\"creation_date\", 0)).strftime(\"%Y-%m-%d\"),\n",
    "        \"owner_reputation\": q.get(\"owner\", {}).get(\"reputation\", 0),\n",
    "        \"owner_user_id\": q.get(\"owner\", {}).get(\"user_id\", 0),\n",
    "    })\n",
    "\n",
    "print(f\"Processed {len(processed_data)} questions\")\n",
    "print(\"\\nSample processed data:\")\n",
    "print(json.dumps(processed_data[0], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f044d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Spark Session is active (recreate if stopped)\n",
    "try:\n",
    "    spark.sparkContext._jsc\n",
    "except:\n",
    "    print(\"SparkSession not active. Recreating...\")\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"StackOverflow-Analytics\") \\\n",
    "        .config(\"spark.driver.memory\", \"4g\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "        .getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    print(\"SparkSession recreated successfully!\")\n",
    "\n",
    "# Create Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"question_id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"body\", StringType(), True),\n",
    "    StructField(\"tags\", ArrayType(StringType()), True),\n",
    "    StructField(\"tags_str\", StringType(), True),\n",
    "    StructField(\"score\", IntegerType(), True),\n",
    "    StructField(\"view_count\", IntegerType(), True),\n",
    "    StructField(\"answer_count\", IntegerType(), True),\n",
    "    StructField(\"is_answered\", IntegerType(), True),\n",
    "    StructField(\"creation_date\", StringType(), True),\n",
    "    StructField(\"owner_reputation\", IntegerType(), True),\n",
    "    StructField(\"owner_user_id\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "df = spark.createDataFrame(processed_data, schema)\n",
    "\n",
    "# Additional transformations\n",
    "df = df.withColumn(\"creation_date\", F.to_date(\"creation_date\")) \\\n",
    "       .withColumn(\"year\", F.year(\"creation_date\")) \\\n",
    "       .withColumn(\"month\", F.month(\"creation_date\")) \\\n",
    "       .withColumn(\"title_length\", F.length(\"title\")) \\\n",
    "       .withColumn(\"body_length\", F.length(\"body\")) \\\n",
    "       .withColumn(\"tag_count\", F.size(\"tags\"))\n",
    "\n",
    "# Handle missing values (Preprocessing)\n",
    "df = df.fillna({\n",
    "    \"score\": 0,\n",
    "    \"view_count\": 0,\n",
    "    \"answer_count\": 0,\n",
    "    \"owner_reputation\": 0,\n",
    "    \"title\": \"\",\n",
    "    \"body\": \"\"\n",
    "})\n",
    "\n",
    "print(f\"DataFrame created with {df.count()} rows\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Parquet (File System requirement)\n",
    "output_path = \"stackoverflow_questions_parquet\"\n",
    "df.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").parquet(output_path)\n",
    "print(f\"Data saved to Parquet: {output_path}\")\n",
    "\n",
    "# Show sample data\n",
    "df.select(\"question_id\", \"title\", \"score\", \"view_count\", \"tag_count\").show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b543b5b",
   "metadata": {},
   "source": [
    "## 4. EDA - Exploratory Data Analysis\n",
    "\n",
    "Analisis eksplorasi data untuk memahami karakteristik dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062baa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY STATISTICS - STACK OVERFLOW QUESTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stats = df.select(\n",
    "    F.count(\"*\").alias(\"Total Questions\"),\n",
    "    F.avg(\"score\").alias(\"Avg Score\"),\n",
    "    F.avg(\"view_count\").alias(\"Avg Views\"),\n",
    "    F.avg(\"answer_count\").alias(\"Avg Answers\"),\n",
    "    F.sum(\"is_answered\").alias(\"Answered Questions\"),\n",
    "    F.avg(\"tag_count\").alias(\"Avg Tags\"),\n",
    "    F.avg(\"title_length\").alias(\"Avg Title Length\"),\n",
    "    F.avg(\"body_length\").alias(\"Avg Body Length\"),\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Total Questions: {stats['Total Questions']}\")\n",
    "print(f\"Average Score: {stats['Avg Score']:.2f}\")\n",
    "print(f\"Average Views: {stats['Avg Views']:.0f}\")\n",
    "print(f\"Average Answers: {stats['Avg Answers']:.2f}\")\n",
    "print(f\"Answered Questions: {stats['Answered Questions']}\")\n",
    "print(f\"Average Tags per Question: {stats['Avg Tags']:.2f}\")\n",
    "print(f\"Average Title Length: {stats['Avg Title Length']:.0f} chars\")\n",
    "print(f\"Average Body Length: {stats['Avg Body Length']:.0f} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e58c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "pdf = df.toPandas()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Score Distribution\n",
    "axes[0, 0].hist(pdf['score'], bins=30, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Score Distribution')\n",
    "axes[0, 0].set_xlabel('Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. Top Tags\n",
    "tag_counts = pdf['tags'].explode().value_counts().head(10)\n",
    "axes[0, 1].barh(tag_counts.index, tag_counts.values, color='coral')\n",
    "axes[0, 1].set_title('Top 10 Tags')\n",
    "axes[0, 1].set_xlabel('Count')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# 3. Views vs Score\n",
    "axes[1, 0].scatter(pdf['view_count'], pdf['score'], alpha=0.5, c='green')\n",
    "axes[1, 0].set_title('Views vs Score')\n",
    "axes[1, 0].set_xlabel('View Count')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "\n",
    "# 4. Answered vs Unanswered\n",
    "answered_counts = pdf['is_answered'].value_counts()\n",
    "labels = ['Answered' if x == 1 else 'Unanswered' for x in answered_counts.index]\n",
    "axes[1, 1].pie(answered_counts.values, labels=labels, autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'])\n",
    "axes[1, 1].set_title('Answered vs Unanswered')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ba535",
   "metadata": {},
   "source": [
    "## 5. Spark SQL - CTE, Subquery, dan Hint\n",
    "\n",
    "Demonstrasi penggunaan fitur Spark SQL yang advanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register DataFrame as temp view\n",
    "df.createOrReplaceTempView(\"questions\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SPARK SQL - CTE, SUBQUERY, DAN SQL HINT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================\n",
    "# QUERY 1: CTE + Subquery + BROADCAST Hint\n",
    "# ============================================================\n",
    "sql_query_1 = \"\"\"\n",
    "-- CTE untuk filter high score questions\n",
    "WITH high_score AS (\n",
    "    SELECT question_id, title, score, view_count, answer_count\n",
    "    FROM questions\n",
    "    WHERE score >= 5\n",
    "),\n",
    "-- CTE untuk statistik per bulan\n",
    "monthly_stats AS (\n",
    "    SELECT \n",
    "        year, month,\n",
    "        COUNT(*) as question_count,\n",
    "        AVG(score) as avg_score,\n",
    "        AVG(view_count) as avg_views\n",
    "    FROM questions\n",
    "    GROUP BY year, month\n",
    ")\n",
    "-- Query utama dengan BROADCAST hint dan subquery\n",
    "SELECT /*+ BROADCAST(monthly_stats) */\n",
    "    h.question_id,\n",
    "    h.title,\n",
    "    h.score,\n",
    "    h.view_count,\n",
    "    ROUND(m.avg_score, 2) as monthly_avg_score\n",
    "FROM high_score h\n",
    "CROSS JOIN monthly_stats m\n",
    "WHERE h.score > (SELECT AVG(score) FROM questions)\n",
    "ORDER BY h.score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nðŸ“Š Query 1: CTE + Subquery + BROADCAST Hint\")\n",
    "print(\"-\" * 70)\n",
    "result_1 = spark.sql(sql_query_1)\n",
    "display(result_1.toPandas())\n",
    "\n",
    "# ============================================================\n",
    "# QUERY 2: COALESCE Hint untuk optimasi partisi\n",
    "# ============================================================\n",
    "sql_query_2 = \"\"\"\n",
    "SELECT /*+ COALESCE(2) */\n",
    "    year,\n",
    "    month,\n",
    "    COUNT(*) as total_questions,\n",
    "    ROUND(AVG(score), 2) as avg_score,\n",
    "    ROUND(AVG(view_count), 0) as avg_views,\n",
    "    SUM(answer_count) as total_answers,\n",
    "    SUM(CASE WHEN is_answered = 1 THEN 1 ELSE 0 END) as answered_count\n",
    "FROM questions\n",
    "GROUP BY year, month\n",
    "ORDER BY year DESC, month DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nðŸ“Š Query 2: Monthly Statistics dengan COALESCE Hint\")\n",
    "print(\"-\" * 70)\n",
    "result_2 = spark.sql(sql_query_2)\n",
    "display(result_2.toPandas())\n",
    "\n",
    "# ============================================================\n",
    "# QUERY 3: REPARTITION Hint + Window Function\n",
    "# ============================================================\n",
    "sql_query_3 = \"\"\"\n",
    "SELECT /*+ REPARTITION(4) */\n",
    "    question_id,\n",
    "    title,\n",
    "    score,\n",
    "    view_count,\n",
    "    RANK() OVER (ORDER BY score DESC) as score_rank,\n",
    "    DENSE_RANK() OVER (ORDER BY view_count DESC) as views_rank,\n",
    "    ROUND(PERCENT_RANK() OVER (ORDER BY score), 4) as score_percentile\n",
    "FROM questions\n",
    "ORDER BY score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nðŸ“Š Query 3: Window Functions dengan REPARTITION Hint\")\n",
    "print(\"-\" * 70)\n",
    "result_3 = spark.sql(sql_query_3)\n",
    "display(result_3.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c561e3",
   "metadata": {},
   "source": [
    "## 6. RDD Operations - MapReduce\n",
    "\n",
    "Demonstrasi operasi RDD: map, flatMap, reduceByKey, groupByKey, combineByKey, aggregateByKey, partitionBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ade35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RDD OPERATIONS - MAP, FLATMAP, REDUCEBYKEY\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RDD OPERATIONS - MAPREDUCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get RDD from DataFrame\n",
    "rdd = df.select(\"question_id\", \"tags_str\", \"score\", \"view_count\").rdd\n",
    "\n",
    "def extract_tags(tags_str):\n",
    "    \"\"\"Extract individual tags from tag string.\"\"\"\n",
    "    if tags_str:\n",
    "        return re.findall(r'<([^>]+)>', tags_str)\n",
    "    return []\n",
    "\n",
    "# ============================================================\n",
    "# 1. MAP + FLATMAP + REDUCEBYKEY - Tag Count\n",
    "# ============================================================\n",
    "print(\"\\nðŸ“Š 1. MAP + FLATMAP + REDUCEBYKEY - Tag Count\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# FlatMap untuk extract tags, Map untuk create pairs, ReduceByKey untuk count\n",
    "tag_counts_rdd = (\n",
    "    df.select(\"tags_str\")\n",
    "    .rdd\n",
    "    .flatMap(lambda row: extract_tags(row[\"tags_str\"]))  # flatMap\n",
    "    .map(lambda tag: (tag, 1))  # map\n",
    "    .reduceByKey(lambda a, b: a + b)  # reduceByKey\n",
    "    .sortBy(lambda x: -x[1])\n",
    ")\n",
    "\n",
    "# Convert to Pandas DataFrame for table display\n",
    "tag_counts_list = tag_counts_rdd.take(15)\n",
    "tag_counts_df = pd.DataFrame(tag_counts_list, columns=[\"Tag\", \"Count\"])\n",
    "tag_counts_df.index = range(1, len(tag_counts_df) + 1)\n",
    "tag_counts_df.index.name = \"Rank\"\n",
    "display(tag_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. GROUPBYKEY - Questions per Tag\n",
    "# ============================================================\n",
    "print(\"\\nðŸ“Š 2. GROUPBYKEY - Questions per Tag\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# GroupByKey untuk mengelompokkan question_id per tag\n",
    "questions_by_tag_rdd = (\n",
    "    df.select(\"question_id\", \"tags_str\")\n",
    "    .rdd\n",
    "    .flatMap(lambda row: [(tag, row[\"question_id\"]) for tag in extract_tags(row[\"tags_str\"])])\n",
    "    .groupByKey()  # groupByKey\n",
    "    .map(lambda x: (x[0], list(x[1]), len(list(x[1]))))\n",
    "    .sortBy(lambda x: -x[2])\n",
    ")\n",
    "\n",
    "# Convert to Pandas DataFrame for table display\n",
    "groupby_list = [(tag, count) for tag, qids, count in questions_by_tag_rdd.take(15)]\n",
    "groupby_df = pd.DataFrame(groupby_list, columns=[\"Tag\", \"Question Count\"])\n",
    "groupby_df.index = range(1, len(groupby_df) + 1)\n",
    "groupby_df.index.name = \"Rank\"\n",
    "display(groupby_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b9494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. COMBINEBYKEY - Tag Statistics (Min, Max, Sum, Count, Avg)\n",
    "# ============================================================\n",
    "print(\"\\nðŸ“Š 3. COMBINEBYKEY - Tag Statistics\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# CombineByKey untuk menghitung statistik per tag\n",
    "def create_combiner(score):\n",
    "    \"\"\"Create initial combiner: (min, max, sum, count)\"\"\"\n",
    "    return (score, score, score, 1)\n",
    "\n",
    "def merge_value(acc, score):\n",
    "    \"\"\"Merge a new value into accumulator.\"\"\"\n",
    "    return (min(acc[0], score), max(acc[1], score), acc[2] + score, acc[3] + 1)\n",
    "\n",
    "def merge_combiners(acc1, acc2):\n",
    "    \"\"\"Merge two accumulators.\"\"\"\n",
    "    return (min(acc1[0], acc2[0]), max(acc1[1], acc2[1]), acc1[2] + acc2[2], acc1[3] + acc2[3])\n",
    "\n",
    "tag_stats_rdd = (\n",
    "    df.select(\"tags_str\", \"score\")\n",
    "    .rdd\n",
    "    .flatMap(lambda row: [(tag, row[\"score\"]) for tag in extract_tags(row[\"tags_str\"])])\n",
    "    .combineByKey(create_combiner, merge_value, merge_combiners)  # combineByKey\n",
    "    .map(lambda x: (x[0], x[1][0], x[1][1], x[1][2], x[1][3], round(x[1][2]/x[1][3], 2)))\n",
    "    .sortBy(lambda x: -x[5])  # Sort by average\n",
    ")\n",
    "\n",
    "# Convert to Pandas DataFrame for table display\n",
    "combinebykey_list = tag_stats_rdd.take(15)\n",
    "combinebykey_df = pd.DataFrame(\n",
    "    combinebykey_list, \n",
    "    columns=[\"Tag\", \"Min Score\", \"Max Score\", \"Total Score\", \"Count\", \"Avg Score\"]\n",
    ")\n",
    "combinebykey_df.index = range(1, len(combinebykey_df) + 1)\n",
    "combinebykey_df.index.name = \"Rank\"\n",
    "display(combinebykey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93956237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. AGGREGATEBYKEY - Average Score per Tag\n",
    "# ============================================================\n",
    "print(\"\\nðŸ“Š 4. AGGREGATEBYKEY - Average Score per Tag\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# AggregateByKey untuk menghitung rata-rata skor per tag\n",
    "avg_score_rdd = (\n",
    "    df.select(\"tags_str\", \"score\")\n",
    "    .rdd\n",
    "    .flatMap(lambda row: [(tag, row[\"score\"]) for tag in extract_tags(row[\"tags_str\"])])\n",
    "    .aggregateByKey(\n",
    "        (0, 0),  # Initial value: (sum, count)\n",
    "        lambda acc, score: (acc[0] + score, acc[1] + 1),  # Merge value\n",
    "        lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])  # Merge combiners\n",
    "    )\n",
    "    .map(lambda x: (x[0], x[1][0], x[1][1], round(x[1][0] / x[1][1], 2) if x[1][1] > 0 else 0))\n",
    "    .sortBy(lambda x: -x[3])\n",
    ")\n",
    "\n",
    "# Convert to Pandas DataFrame for table display\n",
    "aggregatebykey_list = avg_score_rdd.take(15)\n",
    "aggregatebykey_df = pd.DataFrame(\n",
    "    aggregatebykey_list, \n",
    "    columns=[\"Tag\", \"Total Score\", \"Count\", \"Average Score\"]\n",
    ")\n",
    "aggregatebykey_df.index = range(1, len(aggregatebykey_df) + 1)\n",
    "aggregatebykey_df.index.name = \"Rank\"\n",
    "display(aggregatebykey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. PARTITIONBY - Custom Partitioning\n",
    "# ============================================================\n",
    "print(\"\\nðŸ“Š 5. PARTITIONBY - Custom Partitioning\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# PartitionBy untuk custom partitioning\n",
    "partitioned_rdd = (\n",
    "    df.select(\"tags_str\", \"score\")\n",
    "    .rdd\n",
    "    .flatMap(lambda row: [(tag, row[\"score\"]) for tag in extract_tags(row[\"tags_str\"])])\n",
    "    .partitionBy(4)  # partitionBy with 4 partitions\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    ")\n",
    "\n",
    "print(f\"âœ… Number of partitions: {partitioned_rdd.getNumPartitions()}\")\n",
    "\n",
    "# Convert to Pandas DataFrame for table display\n",
    "partition_list = partitioned_rdd.sortBy(lambda x: -x[1]).take(15)\n",
    "partition_df = pd.DataFrame(partition_list, columns=[\"Tag\", \"Total Score\"])\n",
    "partition_df.index = range(1, len(partition_df) + 1)\n",
    "partition_df.index.name = \"Rank\"\n",
    "display(partition_df)\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY TABLE - All RDD Operations\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“‹ SUMMARY: RDD Operations Used\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_data = [\n",
    "    [\"map\", \"Transform each element\", \"tag -> (tag, 1)\"],\n",
    "    [\"flatMap\", \"One-to-many transformation\", \"tags_str -> [tag1, tag2, ...]\"],\n",
    "    [\"reduceByKey\", \"Combine values by key\", \"(tag, 1) -> (tag, count)\"],\n",
    "    [\"groupByKey\", \"Group all values by key\", \"(tag, qid) -> (tag, [qid1, qid2, ...])\"],\n",
    "    [\"combineByKey\", \"Custom aggregation by key\", \"(tag, score) -> (tag, min, max, sum, count)\"],\n",
    "    [\"aggregateByKey\", \"Aggregate with initial value\", \"(tag, score) -> (tag, sum, count, avg)\"],\n",
    "    [\"partitionBy\", \"Custom partitioning\", \"Distribute data across 4 partitions\"],\n",
    "]\n",
    "summary_df = pd.DataFrame(summary_data, columns=[\"Operation\", \"Description\", \"Example\"])\n",
    "summary_df.index = range(1, len(summary_df) + 1)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8bd4a",
   "metadata": {},
   "source": [
    "## 7. NLP - Text Preprocessing\n",
    "\n",
    "Preprocessing teks menggunakan NLTK: tokenization, stopword removal, lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize NLTK components\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text: lowercase, tokenize, remove stopwords, lemmatize.\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    \n",
    "    # Lowercase and remove special characters\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens \n",
    "              if token not in stop_words and len(token) > 2]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Create UDF for Spark\n",
    "@F.udf(ArrayType(StringType()))\n",
    "def preprocess_udf(text):\n",
    "    return preprocess_text(text)\n",
    "\n",
    "# Apply preprocessing\n",
    "df_nlp = df.withColumn(\"title_tokens\", preprocess_udf(F.col(\"title\"))) \\\n",
    "           .withColumn(\"body_tokens\", preprocess_udf(F.col(\"body\"))) \\\n",
    "           .withColumn(\"all_tokens\", F.concat(\"title_tokens\", \"body_tokens\"))\n",
    "\n",
    "print(\"Text Preprocessing Applied:\")\n",
    "df_nlp.select(\"title\", \"title_tokens\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a38e2",
   "metadata": {},
   "source": [
    "## 8. Sentiment Analysis\n",
    "\n",
    "Analisis sentimen pada pertanyaan menggunakan VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807da8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"Get sentiment score and label.\"\"\"\n",
    "    if not text:\n",
    "        return (0.0, \"neutral\")\n",
    "    scores = sia.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return (compound, \"positive\")\n",
    "    elif compound <= -0.05:\n",
    "        return (compound, \"negative\")\n",
    "    else:\n",
    "        return (compound, \"neutral\")\n",
    "\n",
    "# Create UDFs\n",
    "@F.udf(FloatType())\n",
    "def sentiment_score_udf(text):\n",
    "    return float(get_sentiment(text)[0])\n",
    "\n",
    "@F.udf(StringType())\n",
    "def sentiment_label_udf(text):\n",
    "    return get_sentiment(text)[1]\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df_sentiment = df.withColumn(\"sentiment_score\", sentiment_score_udf(F.col(\"title\"))) \\\n",
    "                 .withColumn(\"sentiment_label\", sentiment_label_udf(F.col(\"title\")))\n",
    "\n",
    "# Show results\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "df_sentiment.select(\"title\", \"sentiment_score\", \"sentiment_label\").show(10, truncate=50)\n",
    "\n",
    "# Sentiment distribution\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "df_sentiment.groupBy(\"sentiment_label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda8fea",
   "metadata": {},
   "source": [
    "## 9. TF-IDF Feature Extraction\n",
    "\n",
    "Ekstraksi fitur TF-IDF menggunakan Spark MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, VectorAssembler\n",
    "\n",
    "# Prepare text for TF-IDF\n",
    "df_tfidf = df.withColumn(\"text\", F.concat_ws(\" \", F.col(\"title\"), F.col(\"body\")))\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "df_tokenized = tokenizer.transform(df_tfidf)\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "df_filtered = remover.transform(df_tokenized)\n",
    "\n",
    "# HashingTF\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=1000)\n",
    "df_tf = hashingTF.transform(df_filtered)\n",
    "\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
    "idf_model = idf.fit(df_tf)\n",
    "df_tfidf_final = idf_model.transform(df_tf)\n",
    "\n",
    "print(\"TF-IDF Features Extracted:\")\n",
    "df_tfidf_final.select(\"question_id\", \"title\", \"tfidf_features\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b27379",
   "metadata": {},
   "source": [
    "## 10. Topic Modeling dengan LDA\n",
    "\n",
    "Menggunakan Latent Dirichlet Allocation untuk menemukan topik tersembunyi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# Prepare data for LDA\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"cv_features\", vocabSize=1000, minDF=2.0)\n",
    "cv_model = cv.fit(df_filtered)\n",
    "df_cv = cv_model.transform(df_filtered)\n",
    "\n",
    "# Train LDA model\n",
    "num_topics = 5\n",
    "lda = LDA(k=num_topics, maxIter=10, featuresCol=\"cv_features\")\n",
    "lda_model = lda.fit(df_cv)\n",
    "\n",
    "# Get topics\n",
    "vocab = cv_model.vocabulary\n",
    "topics = lda_model.describeTopics(maxTermsPerTopic=8)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TOPIC MODELING RESULTS (LDA)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "topics_list = topics.collect()\n",
    "for i, row in enumerate(topics_list):\n",
    "    print(f\"\\nTopic {i + 1}:\")\n",
    "    terms = [vocab[idx] for idx in row['termIndices']]\n",
    "    weights = row['termWeights']\n",
    "    for term, weight in zip(terms, weights):\n",
    "        print(f\"  - {term}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4bae0",
   "metadata": {},
   "source": [
    "## 11. Machine Learning - Komparasi 2 Algoritma\n",
    "\n",
    "Membandingkan **Random Forest** dan **Logistic Regression** untuk prediksi kualitas pertanyaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Prepare ML DataFrame\n",
    "# Label: 1 = High quality (score >= 10), 0 = Low quality\n",
    "df_ml = df_tfidf_final.withColumn(\n",
    "    \"label\",\n",
    "    F.when(F.col(\"score\") >= 10, 1.0).otherwise(0.0)\n",
    ")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"tfidf_features\", \"view_count\", \"answer_count\", \"tag_count\"],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "df_ml = assembler.transform(df_ml)\n",
    "\n",
    "print(\"Label Distribution:\")\n",
    "df_ml.groupBy(\"label\").count().show()\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = df_ml.randomSplit([0.7, 0.3], seed=42)\n",
    "print(f\"Training set: {train_df.count()} rows\")\n",
    "print(f\"Test set: {test_df.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ab16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL 1: RANDOM FOREST with Hyperparameter Tuning\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING RANDOM FOREST with CrossValidator\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# Evaluator\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "\n",
    "# CrossValidator\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=param_grid_rf,\n",
    "    evaluator=evaluator_f1,\n",
    "    numFolds=3,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Training Random Forest...\")\n",
    "cv_model_rf = cv_rf.fit(train_df)\n",
    "best_rf = cv_model_rf.bestModel\n",
    "\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getMaxDepth()}\")\n",
    "\n",
    "# Predict\n",
    "rf_predictions = cv_model_rf.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adb0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL 2: LOGISTIC REGRESSION with Hyperparameter Tuning\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING LOGISTIC REGRESSION with CrossValidator\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "# CrossValidator\n",
    "cv_lr = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=param_grid_lr,\n",
    "    evaluator=evaluator_f1,\n",
    "    numFolds=3,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Training Logistic Regression...\")\n",
    "cv_model_lr = cv_lr.fit(train_df)\n",
    "best_lr = cv_model_lr.bestModel\n",
    "\n",
    "print(f\"Best regParam: {best_lr.getRegParam()}\")\n",
    "print(f\"Best elasticNetParam: {best_lr.getElasticNetParam()}\")\n",
    "\n",
    "# Predict\n",
    "lr_predictions = cv_model_lr.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d592d",
   "metadata": {},
   "source": [
    "## 12. Evaluasi Model\n",
    "\n",
    "Evaluasi kedua model dengan metrik: **Accuracy, F1-Score, Precision, Recall, AUC-ROC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "# Evaluators\n",
    "eval_accuracy = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "eval_f1 = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "eval_precision = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "eval_recall = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "eval_auc = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_accuracy = eval_accuracy.evaluate(rf_predictions)\n",
    "rf_f1 = eval_f1.evaluate(rf_predictions)\n",
    "rf_precision = eval_precision.evaluate(rf_predictions)\n",
    "rf_recall = eval_recall.evaluate(rf_predictions)\n",
    "rf_auc = eval_auc.evaluate(rf_predictions)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_accuracy = eval_accuracy.evaluate(lr_predictions)\n",
    "lr_f1 = eval_f1.evaluate(lr_predictions)\n",
    "lr_precision = eval_precision.evaluate(lr_predictions)\n",
    "lr_recall = eval_recall.evaluate(lr_predictions)\n",
    "lr_auc = eval_auc.evaluate(lr_predictions)\n",
    "\n",
    "# Print comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metric':<18} {'Random Forest':>20} {'Logistic Regression':>22}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Accuracy':<18} {rf_accuracy:>20.4f} {lr_accuracy:>22.4f}\")\n",
    "print(f\"{'F1-Score':<18} {rf_f1:>20.4f} {lr_f1:>22.4f}\")\n",
    "print(f\"{'Precision':<18} {rf_precision:>20.4f} {lr_precision:>22.4f}\")\n",
    "print(f\"{'Recall':<18} {rf_recall:>20.4f} {lr_recall:>22.4f}\")\n",
    "print(f\"{'AUC-ROC':<18} {rf_auc:>20.4f} {lr_auc:>22.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Determine best model\n",
    "best_model_name = \"Random Forest\" if rf_f1 >= lr_f1 else \"Logistic Regression\"\n",
    "print(f\"\\nBest Model (by F1-Score): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82befe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Model Comparison\n",
    "metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall', 'AUC-ROC']\n",
    "rf_scores = [rf_accuracy, rf_f1, rf_precision, rf_recall, rf_auc]\n",
    "lr_scores = [lr_accuracy, lr_f1, lr_precision, lr_recall, lr_auc]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, rf_scores, width, label='Random Forest', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, lr_scores, width, label='Logistic Regression', color='coral')\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Comparison: Random Forest vs Logistic Regression')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9608789",
   "metadata": {},
   "source": [
    "## 13. Kesimpulan\n",
    "\n",
    "### Ringkasan Analisis Stack Overflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RINGKASAN KEPATUHAN PERSYARATAN UAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "compliance_summary = \"\"\"\n",
    "1. DATASET 5V (min 3):\n",
    "   - Volume: Data dari Stack Overflow API (ribuan pertanyaan)\n",
    "   - Variety: JSON (terstruktur), teks (tidak terstruktur), tags\n",
    "   - Veracity: Cleaning HTML, handling missing values\n",
    "   - Value: Model prediktif kualitas pertanyaan\n",
    "   \n",
    "2. FILE SYSTEM: Parquet storage (dapat digunakan dengan HDFS)\n",
    "\n",
    "3. BATCH PROCESSING + MAPREDUCE:\n",
    "   - Operasi RDD: map, flatMap, reduceByKey, groupByKey\n",
    "   - combineByKey, aggregateByKey, partitionBy\n",
    "   \n",
    "4. EDA + VISUALISASI: Matplotlib charts, statistik deskriptif\n",
    "\n",
    "5. PREPROCESSING: Casting tipe, fillna, cleaning HTML, tokenization\n",
    "\n",
    "6. SPARK SQL: CTE, subquery, BROADCAST hint\n",
    "\n",
    "7. RDD OPERATIONS: Semua operasi byKey terpenuhi\n",
    "\n",
    "8. ML KOMPARASI 2 ALGORITMA:\n",
    "   - Random Forest Classifier\n",
    "   - Logistic Regression\n",
    "   \n",
    "9. HYPERPARAMETER TUNING:\n",
    "   - CrossValidator + ParamGridBuilder\n",
    "   \n",
    "10. EVALUASI MODEL:\n",
    "    - Accuracy, F1-Score, Precision, Recall, AUC-ROC\n",
    "\"\"\"\n",
    "\n",
    "print(compliance_summary)\n",
    "print(\"=\" * 70)\n",
    "print(\"SEMUA PERSYARATAN UAS TERPENUHI!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb296f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark Session\n",
    "spark.stop()\n",
    "print(\"Spark Session stopped. Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Big Data Mining)",
   "language": "python",
   "name": "bigdata-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
