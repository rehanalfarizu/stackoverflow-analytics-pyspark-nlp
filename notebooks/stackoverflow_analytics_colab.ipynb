{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff65ac5",
   "metadata": {},
   "source": [
    "# Stack Overflow Analytics dengan PySpark dan NLP\n",
    "\n",
    "**UAS - Big Data Predictive Analytics Lanjut**\n",
    "\n",
    "Notebook ini mendemonstrasikan pipeline analisis data Stack Overflow menggunakan:\n",
    "- Apache Spark untuk Big Data Processing\n",
    "- NLP untuk Text Analysis\n",
    "- Machine Learning untuk Predictive Analytics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546c765",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "Install dependencies yang diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install pyspark==3.5.0 pandas numpy nltk matplotlib seaborn wordcloud plotly -q\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "print(\"NLTK data downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17e864",
   "metadata": {},
   "source": [
    "## 2. Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StackOverflow-Analytics\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(\"Spark Session created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511f70d",
   "metadata": {},
   "source": [
    "## 3. Create Sample Dataset\n",
    "\n",
    "Membuat sample data yang merepresentasikan Stack Overflow questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5862e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Stack Overflow Data\n",
    "sample_data = [\n",
    "    (1, \"How to read CSV file in Python using pandas?\", \n",
    "     \"I want to read a CSV file and convert it to DataFrame. What is the best approach?\",\n",
    "     \"<python><pandas><csv>\", 45, 12500, 5, 1, \"2024-01-15\"),\n",
    "    (2, \"JavaScript async await not working properly\",\n",
    "     \"My async function is not waiting for the promise to resolve. Getting undefined.\",\n",
    "     \"<javascript><async-await><promise>\", 32, 8900, 4, 1, \"2024-01-20\"),\n",
    "    (3, \"Docker container networking between containers\",\n",
    "     \"How can I connect two Docker containers so they can communicate with each other?\",\n",
    "     \"<docker><networking><containers>\", 28, 6700, 3, 1, \"2024-02-05\"),\n",
    "    (4, \"Python list comprehension with if else\",\n",
    "     \"How do I write a list comprehension with conditional logic in Python?\",\n",
    "     \"<python><list-comprehension>\", 55, 15000, 6, 1, \"2024-02-10\"),\n",
    "    (5, \"React useState not updating immediately\",\n",
    "     \"State updates are not reflected immediately after calling setState. Why?\",\n",
    "     \"<reactjs><hooks><state>\", 38, 11200, 5, 1, \"2024-02-15\"),\n",
    "    (6, \"SQL JOIN multiple tables with conditions\",\n",
    "     \"How to join three tables with WHERE clause and GROUP BY in SQL?\",\n",
    "     \"<sql><join><mysql>\", 42, 9800, 4, 1, \"2024-02-20\"),\n",
    "    (7, \"Git merge conflict resolution best practices\",\n",
    "     \"What is the best way to resolve merge conflicts in Git without losing changes?\",\n",
    "     \"<git><merge-conflict><version-control>\", 35, 7500, 4, 1, \"2024-03-01\"),\n",
    "    (8, \"Machine learning model overfitting problem\",\n",
    "     \"My neural network is overfitting on training data. How to prevent this?\",\n",
    "     \"<machine-learning><overfitting><deep-learning>\", 48, 13400, 6, 1, \"2024-03-05\"),\n",
    "    (9, \"Kubernetes pod keeps crashing with OOMKilled\",\n",
    "     \"My Kubernetes pod is being killed due to memory limit. How to debug?\",\n",
    "     \"<kubernetes><docker><memory>\", 25, 5600, 3, 1, \"2024-03-10\"),\n",
    "    (10, \"Python pandas merge dataframes on multiple columns\",\n",
    "     \"How to merge two dataframes on multiple columns with different names?\",\n",
    "     \"<python><pandas><dataframe>\", 52, 14200, 5, 1, \"2024-03-15\"),\n",
    "    (11, \"CSS flexbox center align not working\",\n",
    "     \"I am trying to center a div using flexbox but it is not centering properly.\",\n",
    "     \"<css><flexbox><html>\", 22, 4800, 3, 0, \"2024-03-20\"),\n",
    "    (12, \"Node.js express middleware order matters\",\n",
    "     \"Why does the order of middleware in Express.js affect my application?\",\n",
    "     \"<node.js><express><middleware>\", 30, 6200, 3, 1, \"2024-03-25\"),\n",
    "    (13, \"TensorFlow GPU not detected on Windows\",\n",
    "     \"TensorFlow is not recognizing my NVIDIA GPU. CUDA is installed properly.\",\n",
    "     \"<tensorflow><gpu><cuda>\", 18, 4200, 2, 0, \"2024-04-01\"),\n",
    "    (14, \"Apache Spark DataFrame operations slow\",\n",
    "     \"My Spark job is running very slow. How to optimize DataFrame operations?\",\n",
    "     \"<apache-spark><pyspark><performance>\", 40, 8500, 4, 1, \"2024-04-05\"),\n",
    "    (15, \"REST API authentication JWT vs OAuth\",\n",
    "     \"What is the difference between JWT and OAuth for API authentication?\",\n",
    "     \"<rest><authentication><jwt><oauth>\", 65, 18000, 7, 1, \"2024-04-10\"),\n",
    "    (16, \"Why is my Python code so slow?\",\n",
    "     \"My Python script takes too long to run. How can I make it faster?\",\n",
    "     \"<python><performance><optimization>\", -2, 1200, 1, 0, \"2024-04-15\"),\n",
    "    (17, \"Help needed with homework assignment\",\n",
    "     \"Can someone solve this for me? I don't understand the question.\",\n",
    "     \"<python>\", -5, 800, 0, 0, \"2024-04-20\"),\n",
    "    (18, \"Best programming language to learn in 2024\",\n",
    "     \"Which programming language should I learn as a beginner in 2024?\",\n",
    "     \"<programming-languages><career>\", 15, 5500, 8, 0, \"2024-04-25\"),\n",
    "    (19, \"MongoDB aggregation pipeline group by date\",\n",
    "     \"How to group documents by date and calculate sum in MongoDB aggregation?\",\n",
    "     \"<mongodb><aggregation><database>\", 33, 7200, 3, 1, \"2024-05-01\"),\n",
    "    (20, \"AWS Lambda cold start optimization\",\n",
    "     \"How to reduce cold start time for AWS Lambda functions in Python?\",\n",
    "     \"<aws-lambda><python><serverless>\", 45, 9600, 4, 1, \"2024-05-05\"),\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"Id\", IntegerType(), True),\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Body\", StringType(), True),\n",
    "    StructField(\"Tags\", StringType(), True),\n",
    "    StructField(\"Score\", IntegerType(), True),\n",
    "    StructField(\"ViewCount\", IntegerType(), True),\n",
    "    StructField(\"AnswerCount\", IntegerType(), True),\n",
    "    StructField(\"HasAcceptedAnswer\", IntegerType(), True),\n",
    "    StructField(\"CreationDate\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(sample_data, schema)\n",
    "\n",
    "print(f\"Total Questions: {df.count()}\")\n",
    "df.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6895c85",
   "metadata": {},
   "source": [
    "## 4. ETL - Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade843c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF untuk parsing tags\n",
    "@F.udf(ArrayType(StringType()))\n",
    "def parse_tags(tags_str):\n",
    "    if not tags_str:\n",
    "        return []\n",
    "    return re.findall(r'<([^>]+)>', tags_str)\n",
    "\n",
    "# Transform data\n",
    "df_transformed = df \\\n",
    "    .withColumn(\"TagsList\", parse_tags(F.col(\"Tags\"))) \\\n",
    "    .withColumn(\"TagCount\", F.size(\"TagsList\")) \\\n",
    "    .withColumn(\"TitleLength\", F.length(\"Title\")) \\\n",
    "    .withColumn(\"BodyLength\", F.length(\"Body\")) \\\n",
    "    .withColumn(\"TitleWordCount\", F.size(F.split(\"Title\", \" \"))) \\\n",
    "    .withColumn(\"CreationDate\", F.to_date(\"CreationDate\")) \\\n",
    "    .withColumn(\"Year\", F.year(\"CreationDate\")) \\\n",
    "    .withColumn(\"Month\", F.month(\"CreationDate\"))\n",
    "\n",
    "# Add quality label\n",
    "df_transformed = df_transformed.withColumn(\n",
    "    \"QualityLabel\",\n",
    "    F.when((F.col(\"Score\") >= 30) & (F.col(\"HasAcceptedAnswer\") == 1), 2)  # High\n",
    "    .when(F.col(\"Score\") >= 0, 1)  # Medium\n",
    "    .otherwise(0)  # Low\n",
    ")\n",
    "\n",
    "print(\"Transformed Data:\")\n",
    "df_transformed.select(\"Title\", \"Score\", \"TagCount\", \"TitleLength\", \"QualityLabel\").show(10, truncate=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402b7d7",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7fa29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas for visualization\n",
    "pdf = df_transformed.toPandas()\n",
    "\n",
    "# Summary Statistics\n",
    "print(\"=\" * 50)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Questions: {len(pdf)}\")\n",
    "print(f\"Average Score: {pdf['Score'].mean():.2f}\")\n",
    "print(f\"Average Views: {pdf['ViewCount'].mean():.0f}\")\n",
    "print(f\"Questions with Accepted Answer: {pdf['HasAcceptedAnswer'].sum()}\")\n",
    "print(f\"Average Tags per Question: {pdf['TagCount'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Score Distribution\n",
    "axes[0, 0].hist(pdf['Score'], bins=15, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Question Scores', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. Quality Distribution\n",
    "quality_labels = ['Low', 'Medium', 'High']\n",
    "quality_counts = pdf['QualityLabel'].value_counts().sort_index()\n",
    "colors = ['#ff6b6b', '#ffd93d', '#6bcb77']\n",
    "axes[0, 1].pie(quality_counts, labels=quality_labels, autopct='%1.1f%%', colors=colors)\n",
    "axes[0, 1].set_title('Question Quality Distribution', fontsize=12)\n",
    "\n",
    "# 3. Score vs Views\n",
    "axes[1, 0].scatter(pdf['Score'], pdf['ViewCount'], alpha=0.7, c='steelblue')\n",
    "axes[1, 0].set_title('Score vs View Count', fontsize=12)\n",
    "axes[1, 0].set_xlabel('Score')\n",
    "axes[1, 0].set_ylabel('View Count')\n",
    "\n",
    "# 4. Questions by Month\n",
    "monthly = pdf.groupby('Month').size()\n",
    "axes[1, 1].bar(monthly.index, monthly.values, color='steelblue')\n",
    "axes[1, 1].set_title('Questions by Month', fontsize=12)\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag Analysis\n",
    "from collections import Counter\n",
    "\n",
    "# Flatten all tags\n",
    "all_tags = [tag for tags in pdf['TagsList'] for tag in tags]\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "print(\"Top 10 Most Popular Tags:\")\n",
    "print(\"-\" * 30)\n",
    "for tag, count in tag_counts.most_common(10):\n",
    "    print(f\"{tag}: {count}\")\n",
    "\n",
    "# Tag WordCloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800, height=400,\n",
    "    background_color='white',\n",
    "    colormap='viridis'\n",
    ").generate_from_frequencies(tag_counts)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Stack Overflow Tags Word Cloud', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464d5a4",
   "metadata": {},
   "source": [
    "## 6. NLP - Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Title and Body for text analysis\n",
    "df_text = df_transformed.withColumn(\n",
    "    \"CombinedText\",\n",
    "    F.concat_ws(\" \", F.col(\"Title\"), F.col(\"Body\"))\n",
    ")\n",
    "\n",
    "# Clean text\n",
    "@F.udf(StringType())\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_text = df_text.withColumn(\"CleanText\", clean_text(F.col(\"CombinedText\")))\n",
    "\n",
    "print(\"Cleaned Text Sample:\")\n",
    "df_text.select(\"Title\", \"CleanText\").show(3, truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"CleanText\", outputCol=\"Words\")\n",
    "df_tokenized = tokenizer.transform(df_text)\n",
    "\n",
    "# Remove Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "# Add custom tech stopwords\n",
    "stop_words.extend(['want', 'using', 'use', 'get', 'would', 'like', 'need', 'trying'])\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"Words\", outputCol=\"FilteredWords\", stopWords=stop_words)\n",
    "df_filtered = remover.transform(df_tokenized)\n",
    "\n",
    "print(\"Tokenized and Filtered Words:\")\n",
    "df_filtered.select(\"Title\", \"FilteredWords\").show(3, truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f6295",
   "metadata": {},
   "source": [
    "## 7. NLP - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Custom tech lexicon\n",
    "tech_lexicon = {\n",
    "    'solved': 2.0, 'works': 1.5, 'working': 1.0, 'fixed': 2.0, 'perfect': 2.5,\n",
    "    'error': -2.0, 'bug': -1.5, 'broken': -2.0, 'crash': -2.5, 'fail': -2.0,\n",
    "    'slow': -1.5, 'deprecated': -1.0, 'issue': -1.0, 'problem': -1.0\n",
    "}\n",
    "sia.lexicon.update(tech_lexicon)\n",
    "\n",
    "# UDF for sentiment\n",
    "@F.udf(StringType())\n",
    "def get_sentiment(text):\n",
    "    if not text:\n",
    "        return \"neutral\"\n",
    "    scores = sia.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "@F.udf(FloatType())\n",
    "def get_sentiment_score(text):\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    return float(sia.polarity_scores(text)['compound'])\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df_sentiment = df_filtered \\\n",
    "    .withColumn(\"Sentiment\", get_sentiment(F.col(\"CombinedText\"))) \\\n",
    "    .withColumn(\"SentimentScore\", get_sentiment_score(F.col(\"CombinedText\")))\n",
    "\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "df_sentiment.select(\"Title\", \"Sentiment\", \"SentimentScore\").show(10, truncate=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Distribution\n",
    "sentiment_counts = df_sentiment.groupBy(\"Sentiment\").count().toPandas()\n",
    "\n",
    "colors = {'positive': '#6bcb77', 'neutral': '#4d96ff', 'negative': '#ff6b6b'}\n",
    "sentiment_colors = [colors.get(s, 'gray') for s in sentiment_counts['Sentiment']]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(sentiment_counts['Sentiment'], sentiment_counts['count'], color=sentiment_colors)\n",
    "plt.title('Question Sentiment Distribution', fontsize=14)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6be91a",
   "metadata": {},
   "source": [
    "## 8. NLP - TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8eb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "hashingTF = HashingTF(inputCol=\"FilteredWords\", outputCol=\"RawFeatures\", numFeatures=1000)\n",
    "df_tf = hashingTF.transform(df_sentiment)\n",
    "\n",
    "idf = IDF(inputCol=\"RawFeatures\", outputCol=\"TFIDFFeatures\")\n",
    "idf_model = idf.fit(df_tf)\n",
    "df_tfidf = idf_model.transform(df_tf)\n",
    "\n",
    "print(\"TF-IDF Features created successfully!\")\n",
    "df_tfidf.select(\"Title\", \"TFIDFFeatures\").show(3, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4beaf",
   "metadata": {},
   "source": [
    "## 9. Machine Learning - Quality Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Prepare features\n",
    "df_ml = df_tfidf.withColumn(\"label\", F.col(\"QualityLabel\").cast(\"double\"))\n",
    "\n",
    "# Numeric features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"TitleLength\", \"BodyLength\", \"TagCount\", \"TitleWordCount\", \"SentimentScore\"],\n",
    "    outputCol=\"NumericFeatures\"\n",
    ")\n",
    "df_ml = assembler.transform(df_ml)\n",
    "\n",
    "# Combine with TF-IDF\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "final_assembler = VectorAssembler(\n",
    "    inputCols=[\"NumericFeatures\", \"TFIDFFeatures\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "df_final = final_assembler.transform(df_ml)\n",
    "\n",
    "print(\"Features prepared for ML!\")\n",
    "print(f\"Total samples: {df_final.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df96c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, test_df = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training samples: {train_df.count()}\")\n",
    "print(f\"Testing samples: {test_df.count()}\")\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    numTrees=50,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf_model = rf.fit(train_df)\n",
    "print(\"Random Forest model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ac61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = rf_model.transform(test_df)\n",
    "\n",
    "# Evaluate\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# F1 Score\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions\n",
    "print(\"Sample Predictions:\")\n",
    "predictions.select(\"Title\", \"label\", \"prediction\", \"Score\").show(10, truncate=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af6b268",
   "metadata": {},
   "source": [
    "## 10. Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9acaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag Trend Analysis\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Explode tags\n",
    "df_tags = df_transformed.select(\n",
    "    \"Id\", \"Year\", \"Month\", \"Score\", \"ViewCount\",\n",
    "    explode(\"TagsList\").alias(\"Tag\")\n",
    ")\n",
    "\n",
    "# Tag statistics\n",
    "tag_stats = df_tags.groupBy(\"Tag\").agg(\n",
    "    F.count(\"Id\").alias(\"QuestionCount\"),\n",
    "    F.avg(\"Score\").alias(\"AvgScore\"),\n",
    "    F.sum(\"ViewCount\").alias(\"TotalViews\")\n",
    ").orderBy(F.desc(\"QuestionCount\"))\n",
    "\n",
    "print(\"Tag Statistics:\")\n",
    "tag_stats.show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Trend\n",
    "monthly_trend = df_transformed.groupBy(\"Year\", \"Month\").agg(\n",
    "    F.count(\"Id\").alias(\"QuestionCount\"),\n",
    "    F.avg(\"Score\").alias(\"AvgScore\")\n",
    ").orderBy(\"Year\", \"Month\").toPandas()\n",
    "\n",
    "monthly_trend['Period'] = monthly_trend['Year'].astype(str) + '-' + monthly_trend['Month'].astype(str).str.zfill(2)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax1.bar(monthly_trend['Period'], monthly_trend['QuestionCount'], color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Period')\n",
    "ax1.set_ylabel('Question Count', color='steelblue')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(monthly_trend['Period'], monthly_trend['AvgScore'], color='red', marker='o', linewidth=2)\n",
    "ax2.set_ylabel('Average Score', color='red')\n",
    "\n",
    "plt.title('Monthly Question Trend', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013697cd",
   "metadata": {},
   "source": [
    "## 11. Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STACK OVERFLOW ANALYTICS - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1. DATA OVERVIEW\")\n",
    "print(f\"   - Total Questions Analyzed: {df.count()}\")\n",
    "print(f\"   - Date Range: {pdf['CreationDate'].min()} to {pdf['CreationDate'].max()}\")\n",
    "print(f\"   - Unique Tags: {len(tag_counts)}\")\n",
    "print()\n",
    "print(\"2. TOP TECHNOLOGIES\")\n",
    "for i, (tag, count) in enumerate(tag_counts.most_common(5), 1):\n",
    "    print(f\"   {i}. {tag}: {count} questions\")\n",
    "print()\n",
    "print(\"3. QUALITY METRICS\")\n",
    "print(f\"   - High Quality Questions: {(pdf['QualityLabel'] == 2).sum()}\")\n",
    "print(f\"   - Medium Quality Questions: {(pdf['QualityLabel'] == 1).sum()}\")\n",
    "print(f\"   - Low Quality Questions: {(pdf['QualityLabel'] == 0).sum()}\")\n",
    "print()\n",
    "print(\"4. ML MODEL PERFORMANCE\")\n",
    "print(f\"   - Algorithm: Random Forest\")\n",
    "print(f\"   - Accuracy: {accuracy:.2%}\")\n",
    "print(f\"   - F1 Score: {f1:.2%}\")\n",
    "print()\n",
    "print(\"5. KEY INSIGHTS\")\n",
    "print(\"   - Python remains the most discussed technology\")\n",
    "print(\"   - Questions with more tags tend to get higher engagement\")\n",
    "print(\"   - Sentiment analysis helps identify problematic questions\")\n",
    "print()\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c706460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark Session\n",
    "spark.stop()\n",
    "print(\"Spark session stopped. Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
